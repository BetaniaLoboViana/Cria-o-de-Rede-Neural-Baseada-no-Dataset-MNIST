# -*- coding: utf-8 -*-
"""Rede_neural_do_Zero.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QepROtmuDrX788C7UqHl4QSQU4KICslj
"""

import numpy as np
import torch
import torch.nn.functional as F
import torchvision
import matplotlib.pyplot as plt
from time import time
from torchvision import datasets, transforms
from torch import nn, optim

transform = transforms.ToTensor() #conversão da imagem para Tensor

trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)
trainloader= torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)
valloader =torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)

dataiter = iter(trainloader)
imagens, etiquetas = next(dataiter)
plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')

print (imagens[0].shape) #Verificar as dimensões do tensor de cada imagem
print (etiquetas[0].shape) #Verificar as dimensões do tensor de cada etiqueta

class Modelo(nn.Module):
	def __init__(self):
		super(Modelo, self).__init__()
		self.linear1 = nn.Linear(28*28, 128) #Camada de entrada, 784 neuronios que se ligam a 128
		self.linear2 = nn.Linear(128, 64) #Camada interna 1, que se ligam a 64
		self.linear3 = nn.Linear(64, 10) #Camada interna 2, que se ligam a 10
	# Para camada de saida não é necessário definir nada, pois só precisa pegar o output da camada interna 2


	def forward (self,X):
		X = F.relu(self.linear1(X)) #Função de ativação da camada de entrada para a camada interna 1
		X = F.relu(self.linear2(X)) #Função de ativação da camada interna 1 para a camada interna 2
		X = self.linear3(X) #Função de ativação da camada interna 2 para a camada de saída, nesse caso f(x)
		return F.log_softmax(X, dim=1) #dados usados para calcular a perda

def treino(modelo, trainloader, device):
    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)  # define política de atualização dos pesos e das bias
    inicio = time()  # timer para saber o tempo que levou o treino

    criterio = nn.NLLLoss()  # definindo critério para calcular perda
    EPOCHS = 10  # número de epochs que o algoritmo executará
    modelo.train()  # ativando modo treinamento de modelo

    for epoch in range(EPOCHS):
        perda_acumulada = 0  # inicialização da perda acumulada da epoch em questão

        for imagens, etiquetas in trainloader:
            imagens = imagens.view(imagens.shape[0], -1)  # convertendo imagens para vetores de 28*28 casas
            otimizador.zero_grad()  # zerando gradientes por conta do ciclo anterior

            output = modelo(imagens.to(device))  # adicionando os dados no modelo
            perda_instantanea = criterio(output, etiquetas.to(device))  # calculando a perda da epoch em questão

            perda_instantanea.backward()  # backpropagation a partir da perda

            otimizador.step()  # atualizando pesos e bias

            perda_acumulada += perda_instantanea.item()  # atualização da perda acumulada

        # Saída do loop interno (treinamento de um epoch completo)
        print("Epoch {} - Perda resultante: {:.4f}".format(epoch + 1, perda_acumulada / len(trainloader)))

    print("\nTempo de treino (em minutos) =", (time() - inicio) / 60)

def validacao(modelo, valloader, device):
	conta_corretas, conta_todas = 0, 0
	for imagens, etiquetas in valloader:
	  for i in range(len(etiquetas)):
	  	img = imagens[i].view(1, 784)
	  	#desativar autograd para aceleração da validação. grafos dinâmicos tem custo alto
	  	with torch.no_grad():
	  		logps = modelo(img.to(device)) #saida do modelo em escala logaritmica


	  	ps = torch.exp(logps) #converte saida para escala normal
	  	probab = list(ps.cpu().numpy()[0])
	  	etiqueta_pred = probab.index(max(probab)) #converte o tensor em um número, no caso o numero que o modelo previu
	  	etiqueta_certa = etiquetas.numpy()[i]
	  	if(etiqueta_certa==etiqueta_pred): #compara a previsão com o valor certo
	  	  conta_corretas +=1
	  	conta_todas +=1

	print("Total imagens testadas =", conta_todas)
	print("\nPrecisão do modelo ={}%".format(conta_corretas*100/conta_todas))

modelo = Modelo()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
modelo.to(device)

treino(modelo, trainloader, device)